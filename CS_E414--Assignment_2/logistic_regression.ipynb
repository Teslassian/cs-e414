{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn.utils.extmath import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from import_LR import import_LR\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Functions'''\n",
    "def sigmoid(x):\n",
    "    '''Computes the sigmoid function'''\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    return s\n",
    "\n",
    "def hessian(N, d, X, wk, lambda_):\n",
    "    '''Computes the Hessian matrix'''\n",
    "    \n",
    "    u_H = 0\n",
    "    I = np.eye(d)\n",
    "    for n in range(N):\n",
    "        u_H += sigmoid(w.T @ X[:,n,None])  *  (1-sigmoid(w.T @ X[:,n,None]))  *  (X[:,n,None] @ X[:,n,None].T)  +  1/lambda_*I\n",
    " \n",
    "#     m_H = (sigmoid(w.T @ X) * (1-sigmoid(w.T @ X)).T) * (X @ X.T) + 1/lambda_*I  # Experimental\n",
    "\n",
    "#     H = (sigmoid(w.T @ X) @ (1-sigmoid(w.T @ X)).T) * (X @ X.T) + 1/lambda_*I  # Experimental\n",
    "    \n",
    "    return u_H\n",
    "    \n",
    "def gradient_vector(N, X, y, wk, lambda_):\n",
    "    '''Computes the gradient of the negative log-likelihood'''\n",
    "    \n",
    "    u_l = 0\n",
    "    for n in range(N):\n",
    "        u_l += -(y[:,n]-sigmoid(w.T @ X[:,n]))[0] * X[:,n,None]\n",
    "    u_l += 1/lambda_*w\n",
    "    \n",
    "#     l = -((y-sigmoid(w.T @ X)) @ X.T).T + 1/lambda_*w  # Should work\n",
    "      \n",
    "    return u_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Import data'''\n",
    "X, y = import_LR()                       # Input data & labels\n",
    "ones = np.ones((1,X.shape[1]))\n",
    "X = np.vstack([ones, X])\n",
    "epsilon = 1e-10                           # Convergence metric\n",
    "max_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Metrics'''\n",
    "d = X.shape[0]                           # Number of dimensions\n",
    "N = X.shape[1]                           # Number of samples\n",
    "C = list(set(y))                         # Classes\n",
    "lambda_ = 1                              # Regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Matrix initialization'''\n",
    "y = y[np.newaxis,:]\n",
    "w = np.random.randn(d,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental\n",
    "# a = np.random.randint(1,5,(d,d))\n",
    "# print(a)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# print(a[:,0,None]@a[:,0,None].T)\n",
    "# print(a[:,1,None]@a[:,1,None].T)\n",
    "# # print(a[None,0,:]@a[None,0,:].T)\n",
    "# # print(a[None,1,:]@a[None,1,:].T)\n",
    "# print('\\n\\n')\n",
    "\n",
    "# print(np.tensordot(a,a,0).T)\n",
    "# # print(np.tensordot(X,X, axes=1).shape)\n",
    "# # print(np.tensordot(X,X, axes=2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w\n",
      "[[-0.07824337]\n",
      " [-0.05199713]\n",
      " [ 0.98135842]]\n",
      "H\n",
      "[[1154.50055429  -21.63922256   -3.34675121]\n",
      " [ -21.63922256 1419.06946963  163.46696062]\n",
      " [  -3.34675121  163.46696062 1267.91483357]]\n",
      "l\n",
      "[[ -29.43268689]\n",
      " [-523.52315013]\n",
      " [  59.23262015]]\n",
      "i\n",
      "0\n",
      "e\n",
      "0.3376153602048997\n",
      "w\n",
      "[[0.18355041]\n",
      " [1.20052349]\n",
      " [0.75547627]]\n",
      "H\n",
      "[[1117.0446527    -8.17413267  -28.31178889]\n",
      " [  -8.17413267 1157.02829407  -62.46897266]\n",
      " [ -28.31178889  -62.46897266 1277.24153134]]\n",
      "l\n",
      "[[-0.00224929]\n",
      " [-0.00136971]\n",
      " [-0.00085829]]\n",
      "i\n",
      "100\n",
      "e\n",
      "1.7569496742573562e-06\n",
      "w\n",
      "[[0.1835703 ]\n",
      " [1.20053531]\n",
      " [0.75548374]]\n",
      "H\n",
      "[[1117.04373996   -8.17499454  -28.3125499 ]\n",
      " [  -8.17499454 1157.0261458   -62.46930257]\n",
      " [ -28.3125499   -62.46930257 1277.23863559]]\n",
      "l\n",
      "[[-1.23709895e-07]\n",
      " [-6.96567071e-08]\n",
      " [-4.48769556e-08]]\n",
      "i\n",
      "200\n",
      "e\n",
      "9.44497010007549e-11\n"
     ]
    }
   ],
   "source": [
    "'''Newton-Raphson'''\n",
    "i = 0\n",
    "e = 2*epsilon\n",
    "conv = False\n",
    "while ((e > epsilon) and (i < max_iter)):\n",
    "    w_prev = w\n",
    "    H = hessian(N, d, X, w, lambda_)\n",
    "    l = gradient_vector(N, X, y, w, lambda_)\n",
    "    w = w - np.linalg.inv(H) @ l\n",
    "    e = np.linalg.norm(w - w_prev)/np.linalg.norm(w_prev)  # e = np.amax(np.abs(wk1 - wk))\n",
    "    if (i%100==0):\n",
    "        print('w')\n",
    "        print(w)\n",
    "        print('H')\n",
    "        print(H)\n",
    "        print('l')\n",
    "        print(l)\n",
    "        print('i')\n",
    "        print(i)\n",
    "        print('e')\n",
    "        print(e)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {
    "1e995b3cf08a4dde89a4f98d36100b4e": {
     "views": []
    },
    "22e8d02e22734631ac89835a3ee6c264": {
     "views": []
    },
    "4d54b6e490414dbcadd95b8a615fb2a1": {
     "views": []
    },
    "62ba560ca58c4da892117bca7f6fa9a9": {
     "views": []
    },
    "8a08ef3f36ff412f8a9a0eb3d66537ca": {
     "views": []
    },
    "8fc28dcd900f40398066d0bb93b4b02d": {
     "views": [
      {
       "cell_index": 20
      }
     ]
    },
    "92932ec08bea476e8370722ee5d51d51": {
     "views": []
    },
    "9439499ab9484e05abb40497c8389931": {
     "views": []
    },
    "94be00fa834648e29162ff40ec77694e": {
     "views": []
    },
    "cd5fcc64b09b4b6299c3ef8c66065546": {
     "views": []
    },
    "d0df71b154a740c78d52456923df87a3": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "ff27897c2d224808ad8c6e680968cbb5": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
